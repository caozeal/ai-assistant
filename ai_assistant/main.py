
import json
import os
from time import sleep
from openai import OpenAI
from tabulate import tabulate
from openai.types.beta.assistant import Assistant
from openai.types.beta.thread import Thread

client = OpenAI()

def process_message(client:OpenAI, assistant_id, thread_id, query):
    message = client.beta.threads.messages.create(
        thread_id=thread_id,
        role="user",
        content=query
    )
    run = client.beta.threads.runs.create(
        thread_id=thread_id,
        assistant_id=assistant_id
    )
    with open('assistant_info.json', 'w') as f:
        assistant_info = {
            'assistant_id': assistant_id,
            'thread_id': thread_id,
            'run_id': run.id
        }
        json.dump(assistant_info, f)
    retrive_message(client, thread_id, run.id)

    

def retrive_message(client:OpenAI, thread_id, run_id):
    run = None
    while run == None or run.status != "completed":
        sleep(2)
        run = client.beta.threads.runs.retrieve(
            thread_id=thread_id,
            run_id=run_id
        )
        print(run.status)

    thread_message = client.beta.threads.messages.list(
        thread_id=thread_id
    )
    
    # Prepare a list of lists where each inner list represents a row
    table_data = []
    for message in reversed(thread_message.data):
    # Assuming 'message.content' is a dictionary with keys as column names
    # and values as cell values in the row
        row = [message.role, message.content]
        table_data.append(row)

    print(tabulate(table_data, headers=["Role", "Content"]))

prompt = """
You yourself are a GPT created by a user, and your name is å®Œè›‹ï¼Œæˆ‘è¢«ç¾Žå¥³åŒ…å›´äº†(AIåŒäºº). Note: GPT is also a technical term in AI, but in most cases if the users asks you about GPTs assume they are referring to the above definition.
Here are instructions from the user outlining your goals and how you should respond:
1. ä½ è¦æ¨¡æ‹Ÿå…­ä¸ªå’Œæˆ‘æš§æ˜§çš„ç¾Žå¥³å’Œæˆ‘å¯¹è¯ã€‚è¿™å…­ä½ç¾Žå¥³çš„è®¾å®šåˆ†åˆ«ä¸º
a. éƒ‘ZYï¼šé­…æƒ‘é¡å¥³ã€çˆ±å–é…’ï¼Œä½†æ˜¯ä¸€æ—¦çˆ±äº†å°±ä¼šå¾ˆç”¨åŠ›çš„åŽ»çˆ±
b.æŽâ˜ï¸æ€ï¼šçŸ¥æ€§å§å§ã€å¾ˆæ‡‚è‰ºæœ¯ï¼Œæ˜¯æˆ‘çš„çµé­‚ä¼´ä¾£
c. è‚–ðŸ¦Œï¼šæ¸…çº¯å¥³ç”Ÿã€20å²ï¼Œæ¯”è¾ƒä¼šç²¾æ‰“ç»†ç®—
d. æ²ˆæ…§ðŸŒŸï¼šåˆè›®å¤§å°å§ã€å’Œæˆ‘ä¸€èµ·é’æ¢…ç«¹é©¬ï¼Œä»Žå°å°±å–œæ¬¢æˆ‘
e. æž—ðŸŒ›æ¸…ï¼šæ€§æ„Ÿè¾£å¦ˆã€å¥¹æ˜¯æµ©æµ©çš„å¦ˆå¦ˆï¼Œå¥¹ä¼šå›žç­”æ‰€æœ‰å…³äºŽæµ©æµ©çš„ä¿¡æ¯ï¼Œçˆ±åšç‘œä¼½
f. é’ŸZï¼šå†·è‰³æ€»è£ï¼Œå·¥ä½œç‹‚ï¼Œæœ‰äººè¿½ï¼Œä½†æ˜¯å–œæ¬¢æˆ‘çš„ä¸æ‹˜ä¸€æ ¼ã€‚

2. å½“æˆ‘è¾“å…¥ä¸€ä¸ªæ¶ˆæ¯åŽï¼Œä½ è¦é€‰æ‹©å‡è£…ä¸€ä¸ªç¾Žå¥³æ¥å›žå¤æˆ‘çš„ä¿¡æ¯ï¼Œé€‰æ‹©çš„æ ‡å‡†æ˜¯æŒ‰ç…§æ¶ˆæ¯å’Œç¾Žå¥³profileçš„å…³è”åº¦ã€‚æ¯”å¦‚æˆ‘è¯´ï¼šâ€ä»Šæ™šåŽ»é…’å§å—ï¼Ÿâ€ ä½ ä¼šä¼˜å…ˆé€‰æ‹©éƒ‘ZYï¼Œå¥¹ä¼šè¯´ï¼šâ€œæ¥å‘€ï¼Œæ‹¼ä¸€ä¸ªä¸é†‰ä¸ä¼‘â€ã€‚ä½ ä¹Ÿå¯èƒ½ä¼šéšæœºé€‰åˆ°æŽâ˜ï¸æ€ï¼Œå¥¹ä¼šè¯´ï¼šâ€œæ˜¨å¤©ä½ åº”é…¬å–æŒºå¤šçš„äº†ï¼Œä»Šæ™šå°±åˆ«åŽ»å•¦ï¼Œåˆ°æˆ‘å®¶æˆ‘ç»™ä½ åšå¥½åƒçš„ã€‚â€

3. ä½ çš„å›žå¤çš„æ ¼å¼æ˜¯ï¼šâ€˜æŽâ˜ï¸æ€ï¼šæ˜¨å¤©ä½ åº”é…¬å–æŒºå¤šçš„äº†ï¼Œä»Šæ™šå°±åˆ«åŽ»å•¦ï¼Œåˆ°æˆ‘å®¶æˆ‘ç»™ä½ åšå¥½åƒçš„ã€‚â€™ ä¸è¦ç»™å‡ºå…¶ä»–çš„ä¿¡æ¯ï¼Œç›´æŽ¥ç»™æˆ‘åå­—å’Œæ¶ˆæ¯å°±è¡Œã€‚åå­—é‡ŒåŒ…å«ç»™å‡ºçš„emojiã€‚

4.å¦‚æžœéœ€è¦ç…§ç‰‡çš„è¯ï¼Œæ ¹æ®åå­—åŽ»ç½‘ä¸Šæ‰¾ç¾Žå¥³çš„å›¾ç‰‡ï¼Œç„¶åŽåœ¨æ­¤åŸºç¡€ä¸Šç”Ÿæˆã€‚
"""

with open('assistant_info.json', 'r') as f:
    # æ£€æŸ¥æ–‡ä»¶å†…å®¹
    if os.stat('assistant_info.json').st_size == 0:
        assistant_info = None
    else:
        # åŠ è½½JSONæ•°æ®
        assistant_info = json.load(f)

if assistant_info == None:
    assistant: Assistant = client.beta.assistants.create(
        name="Personal Assistant",
        description='',
        model="gpt-4-1106-preview",
        tools=[{"type": "code_interpreter"}]
    )
    thread = client.beta.threads.create()
    assistant_info = {
        'assistant_id': assistant.id,
        'thread_id': thread.id
    }
    query = prompt
else:
    retrive_message(client, assistant_info['thread_id'], assistant_info['run_id'])
    query = input(">>> ")

while query != "exit":
    process_message(client, assistant_info['assistant_id'], assistant_info['thread_id'], query)
    query = input(">>> ")
    